
# **머신러닝 작업 흐름**


예시와 다르게 현실 세계에서는 프로그램에 지정된 데이터 세트이 존재하거나 모델 훈련을 즉시 시작하는 경우가 적다.
현실에서의 문제 예시
* 사진을 공유하는 소셜 네트워크 유형의 개인화된 사진 검색 엔진으로, 수동으로 태그할 필요 없이 모든 사진을 검색
* 채팅 앱의 게시물 중 스팸 및 불쾌한 텍스트 콘텐츠 플래그 표시
* 온라인 라디오 사용자를 위한 음악 추천 시스템 구축
* 전자상거래 웹 사이트에 대한 신용카드 사기 탐지.
* 주어진 시간에 주어진 사용자에게 어떤 광고를 제공할 것인지 결정하기 위해 광고 클릭률을 예측
* 쿠키 제조라인 컨베이어 벨트에 이상 쿠키 플래그 지정
* 위성 이미지를 사용하여 아직 알려지지 않은 고고학 유적지의 위치를 예측


머신러닝의 흐름은 보통 크게 세 부분으로 구성된다.
> **과제 정의**: 문제와 고객에게 필요한 비즈니스 논리를 이해, 데이터 수집 및 파악 후 성능 평가 방법 선택<br>
> **모델 개발**: 머신러닝 모델 준비, 평가 방법과 기준선을 선택하여 과대적합이 가능한 일반화 능력을 갖춘 첫 번째 모델 훈련(가능한 한 최고의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정)<br>
> **모델 배포**: 고객에게 모델 전달. 실제 모델의 성능을 모니터링하고, 차세대 모델을 구축하는 데 필요한 데이터 수집

## **1. 문제 정의**

하고 있는 일의 맥락을 깊게 이해하지 않고는 좋은 모델을 만들 수 없다. 고객이 왜 문제를 해결하려고 하는지, 해결하면 어떤 결과를 얻는지, 모델이 어떻게 사용되고 비즈니스에 어떻게 적용될 것 같은지, 어떤 종류의 데이터를 사용하고 수집할 수 있는지, 비즈니스 문제에 사용될 머신러닝 과제는 무엇인지 등에 대해 고민해봐야 한다.

### **1.1 문제 구체화하기** 

머신러닝 문제를 구체화하기 위해 고객과 많은 대화가 필요하다.

+ 입력 데이터는 무엇이고 어떤 예측 결과가 필요한가? : 데이터 가용성을 제한하고, 직접 데이터를 수집해 주석 달기
+ 어떤 유형의 머신러닝인가? : 이항 분류/다중 클래스 분류/스칼라 또는 벡터 회귀/강화 학습 등 또는 머신러닝을 사용하지 않아도 되는지
> + 사진 검색 엔진 프로젝트 - 멀티클래스, 멀티라벨 분류
> + 스팸 탐지 프로젝트 - 이진 분류(또는 3원 분류)
> + 음악 추천 엔진 - 딥 러닝이 아닌 매트릭스 인수분해(협업 필터링)를 통해 더 잘 처리
> + 카드 사기 탐지 사업 - 이진 분류
> + 클릭률 예측 프로젝트 - 스칼라 회귀
> + 이상 쿠키 탐지 - 이진 분류 작업(객체 탐지 모델이 필요)
> + 위성 이미지에서 새로운 고고학 유적지를 찾는 프로젝트 - 이미지 유사성 순위 매기기 
+ 기존 해결법은 어떤 형태인가? : 어떤 시스템이 구축되어 있는지, 작동법은 어떤지 이해
+ 특별한 제약 조건이 있는가? : 세부적인 상황에서 지연 시간 제약까지 다양

<br>
조사 후 가설을 설정한다. 모델을 갖추기 전까지는 가설일 뿐이며 검증되거나 무효화 될 수 있다. 
+ 입력이 주어지면 목표를 예측할 수 있다. 
+ 사용 가능한(또는 곧 수집할) 데이터가 입력과 대상 간의 관계를 학습하는 데 충분한 정보를 제공한다.

### **1.2 데이터세트 모으기**

다음은 가장 오래 걸리고 비용이 많이 드는 데이터 수집 단계이다.

* 사진 검색 엔진 프로젝트 - 분류하려는 레이블 세트를 선택, 10,000개의 공통 이미지 카테고리를 설정한다. 그런 다음 이 세트의 레이블로 사용자가 업로드한 과거 이미지 수십만 개에 수동으로 태그를 지정한다.
* 채팅앱 스팸탐지 사업 - 사용자 대화는 암호화되어 있어 모델 훈련에 사용할 수 없다. 별도의 액세스 권한을 얻어 수만 개의 공개 게시물에 대한 데이터 세트를 수동으로 태그하고 스팸, 불쾌감 또는 허용 가능한 태그를 지정한다.
* 음악 추천 엔진 & 클릭률 예측 프로젝트 - 사용자의 기록을 사용, 새로운 데이터를 수집할 필요가 없다.
* 쿠키 flagging 모델 - 컨베이어 벨트에 카메라를 설치해 수만 개의 이미지를 수집, 수동으로 이 이미지에 레이블을 붙여야 한다. (공장 사람들 훈련 시키기)
* 위성사진 프로젝트 - 수천 개 장소의 데이터 베이스를 수집, 각 장소에 대해 다른 기상 조건에서 찍은 기존 위성 사진도 필요.

좋은 모델을 만들기 위해서는 알고리즘 보다도 많은 데이터가 필요하다. 
모델의 일반화 기능은 거의 전적으로 모델의 데이터(보유한 데이터 포인트 수, 레이블의 안정성, 기능의 품질 등)에 따라 학습된다 


**데이터 주석 환경에 투자하기**<br>
지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후, 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요하다.
데이터 주석 공정에 따라 모델의 품질을 결정된다. 아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제가 어렵다는 점에 주의한다.
* 데이터에 주석을 직접 달아야 하는가?
* 라벨을 모으기 위해 Mechanical Turk와 같은 크라우드소싱 플랫폼을 사용해야 하는가?
* 데이터 레이블링 전문 회사의 서비스를 사용해야 하는가? 

<br>
최상의 옵션을 선택하려면 작업 중인 제약 조건을 고려해야 한다. 
* 데이터 레이블 작성자가 전문가여야 하는가?또는 데이터에 주석을 달 수 있는 사람이 있는가? 
* 데이터에 주석을 달 때 전문 지식을 교육할 수 있는가? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있는가?
* 전문가가 주석을 작성하는 방법을 알고 있는가? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없다.

또한, 데이터에 레이블을 붙이기로 결정한 경우 주석을 작성하는데 어떤 소프트웨어를 사용할 것인가? 직접 만들어야 할 수도 있지만, 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있다.

**비대표 데이터 주의하기**<br>
머신러닝 모델은 이전에 본 것과 비슷한 입력만 이해할 수 있어 훈련에 사용되는 데이터는 생산 데이터의 "**대표**"여야 한다. 가능하면 모델이 사용될 환경에서 직접 데이터를 수집한다. 생산 데이터에 대한 훈련이 가능하지 않다면 훈련 데이터와 생산 데이터가 어떻게 다른지 이해하고 차이를 수정해야 한다. 머신러닝은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 주의해야 한다.

*Concpet drift*
* 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생. : 과거 데이터의 표현 방법이 현재와 달라 모델이 제대로 수행되지 못할 가능성이 높음
* 변화가 빠르게 자주 발생하는 경우 극심함
* 해결을 위해 지속적인 데이터 수집, 주석 및 모델 재교육이 필요

*참고: 샘플링 편향의 문제* <br>
샘플링 편향은 데이터 수집 과정에서 예측하려는 것과 상호작용할 때 발생한다.

### **1.3 데이터 이해하기**

모델 훈련 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고 잠재적인 문제를 선별해야 한다. 
* 데이터에 이미지 또는 자연어 텍스트가 포함되어 있는 경우 : 샘플 몇 개(및 해당 레이블)를 직접 살펴보기
* 데이터에 숫자 모양이 포함되어 있는 경우 : 모양의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하기
* 데이터에 위치 정보가 포함되어 있는 경우 : 지도에 표시하여 뚜렷한 패턴 확인하기
* 일부 샘플에 일부 형상에 대한 결측값이 있는 경우: 데이터를 준비할 때 해결해야 한다.
* 분류 문제일 경우 : 데이터에 있는 각 클래스의 인스턴스 수를 파악하기(클래스가 비슷하게 표현되지 않는다면 불균형이 있을 수 있음)
* "타겟 누수(target leaking)"가 있는 경우 : 실제로 운영에서 데이터에 사용할 수 없는 대상(암호화된 정보)에 대한 정보를 제공하는지 확인하기, 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 항상 확인.

### **1.4 성공 평가 방법 선택하기**

프로젝트에서 성공을 거두려면 먼저 성공이 무엇인지 정의해야 한다. 성공을 위한 지표는 프로젝트 전반에 걸쳐 모든 기술적 선택에 영향을 미친다. 이 지표는 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 합니다. 

> 모든 클래스가 동일한 확률의 균형 분류 문제의 경우 : "수신기 조작 특성 곡선(ROC AUC)" 아래의 정확도와 영역이 일반적인 지표이다.<br>
> 클래스 불균형 문제, ranking 문제, 다중 레이블 분류의 경우 : 정밀도 및 재현율 뿐만 아니라 가중치의 정확도 또는 ROC AUC를 사용할 수 있다.<br>
> 또는 자신만의 사용자 지정 메트릭을 정의해야 하는 경우

## **2. 모델 개발** 
진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있다. 

### **2.1 데이터 준비**
데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 한다. 여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다.<br>
이때 전처리 기술은 도메인마다 다르다.(예: 텍스트 데이터 또는 이미지 데이터)
<br>
**벡터화**<br>
신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 한다. <br>
데이터 벡터화 : 소리, 이미지, 텍스트 등의 데이터를 텐서로 전환하는 것.
+ 텍스트 분류에서는 정수 목록(단어 시퀀스를 나타냄)으로 표현된 텍스트에서 시작하여 원핫 인코딩을 사용하여 'float32' 데이터의 텐서로 변환했다. 
<br>
**값 정규화**<br>
일반적으로 사용하는 신경망 데이터나 이기종 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 입력하는 것은 안전하지 않다. 네트워크가 수렴되지 않을 수 있기 때문이다.<br>

네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 한다.
* 작은 값 사용 — 일반적으로 대부분의 값은 0-1 범위여야 한다.
* 균일화 - 즉, 모든 형상이 거의 동일한 범위의 값을 가져야 한다.

<br>
또한 다음과 같은 엄격한 정규화 방법이 일반적이며 항상 필요한 것은 아니지만 도움이 될 수 있습니다. 
* 평균이 0이 되도록 각 특성을 독립적으로 정규화한다. 
* 표준 편차가 1이 되도록 각 특성을 독립적으로 정규화한다.

```python
# NumPy array로 정규화 하기
x -= x.mean(axis=0)
x /= x.std(axis=0)
```

<br>
**결측값 처리**<br>
때때로 데이터에 결측값이 있을 수 있다. 결측값을 완전히 삭제할 수도 있지만 반드시 삭제할 필요는 없다. 
* 특성이 범주형인 경우 : "값이 누락되었습니다"를 의미하는 새 범주를 만든다.(모델은 타겟에 대해 이것이 내포하는 의미를 자동으로 학습한다.)
* 특성이 숫자일 경우 : "0"과 같은 임의의 값을 입력하지 않는다. 모델 일반화에 어려움이 생겨 데이터의 평균값 또는 중위값으로 바꾸는 것이 좋다. <br>
테스트 데이터에 결측값이 있을 때 네트워크는 결측값을 무시하고 학습하지 않는다. 

테스트 데이터에 범주형 결측 기능이 있을 것으로 예상되지만 네트워크가 결측값 없이 데이터에 대해 학습된 경우, 네트워크는 결측값을 무시하는 방법을 배우지 않습니다. 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 합니다. 일부 교육 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.

### **2.2 평가규약 선택** 

이전 장에서 학습한 바와 같이 모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 안내됩니다. 검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것입니다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다. 

5장에서는 세 가지 일반적인 평가 프로토콜을 검토했습니다. 
* 홀드아웃 유효성 검사 세트 유지 - 데이터가 많을 때 사용하는 방법 
* K-폴드 교차 검증 수행 — 홀드아웃 유효성 검사가 신뢰할 수 없을 정도로 샘플 수가 적을 때 올바른 선택 
* 반복 K-폴드 검증 수행 - 데이터가 거의 없을 때 매우 정확한 모델 평가 수행 

이것들 중 하나만 골라. 대부분의 경우 첫 번째 방법은 충분히 효과가 있을 것입니다. 앞에서 배웠듯이, 항상 검증 세트의 대표성에 유의하고 교육 세트와 검증 세트 사이에 중복 샘플이 없도록 주의하십시오.

### **2.3 기준선 박치기** 
모형 자체에 대한 작업을 시작하면 5장에서 살펴본 것처럼 통계적 검정력을 달성하는 것이 초기 목표입니다. 즉, 간단한 기준선을 능가할 수 있는 작은 모형을 개발하는 것입니다. 

이 단계에서 가장 중요한 세 가지 사항은 다음과 같습니다. 
* 유용한 기능이 없는 기능을 걸러내고(기능 선택) 문제에 대한 지식을 활용하여 유용한 새로운 기능을 개발합니다. 
* 올바른 이전 아키텍처 선택: 어떤 유형의 모델 아키텍처를 사용할 예정입니까? 촘촘하게 연결된 네트워크, 컨브넷, 반복적인 신경 네트워크, 트랜스포머? 딥러닝은 과제를 위한 좋은 접근법인가요, 아니면 다른 것을 사용해야 하나요? 
* 충분한 교육 구성 선택—어떤 손실 기능을 사용해야 합니까? 배치 크기와 학습률은 어떻게 됩니까?

**참고: 올바른 손실 기능 선택**

문제에 대한 성공을 측정하는 메트릭에 대해 직접 최적화하지 못하는 경우가 많습니다. 메트릭을 손실 함수로 바꾸는 쉬운 방법이 없을 때도 있습니다. 결국 손실 함수는 데이터의 작은 배치(이상적으로 손실 함수는 단일 데이터 포인트만큼만 계산 가능해야 함)가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 합니다. 예를 들어, 널리 사용되는 분류 지표 ROC AUC는 직접 최적화될 수 없습니다. 따라서 분류 작업에서 교차 엔트로피와 같은 ROC AUC의 프록시 메트릭에 최적화하는 것이 일반적이다. 일반적으로 교차 엔트로피가 낮을수록 ROC AUC가 더 높아지기를 바랄 수 있습니다. 

표 6.1은 몇 가지 일반적인 문제 유형에 대한 마지막 계층 활성화 및 손실 함수를 선택하는 데 도움이 될 수 있습니다. 

**표 6.1. 모형에 적합한 마지막 계층 활성화 및 손실 함수 선택()**

대부분의 문제에서 시작할 수 있는 기존 템플릿이 있습니다. 스팸 탐지기, 음악 추천 엔진 또는 이미지 분류기를 만든 첫 번째 사람은 아닙니다. 선행 기술을 조사하여 작업에서 가장 잘 수행할 수 있는 기능 엔지니어링 기술과 모델 아키텍처를 식별하십시오. 

통계적 힘을 얻는 것이 항상 가능한 것은 아닙니다. 합리적인 아키텍처를 여러 번 시도해도 단순한 기준선을 넘을 수 없다면 입력 데이터에 질문에 대한 답이 없는 것일 수 있습니다. 두 가지 가설을 세우고 있다는 것을 기억하십시오. 
* 입력이 주어지면 출력을 예측할 수 있다는 가설을 세웁니다. 
* 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다. 
이 가설들이 거짓일 가능성이 높으며, 이 경우 당신은 처음부터 다시 시작해야 한다.

### **2.4 스케일업: 지나치게 적합한 모델 개발**

일단 통계적 힘을 가진 모델을 얻으면, 질문은 여러분의 모델이 충분히 강력하냐는 것입니다. 그것은 당면한 문제를 적절하게 모델링하기에 충분한 레이어와 파라미터를 가지고 있나요? 예를 들어, 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이입니다. 이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델입니다. 이 국경이 어디에 있는지 알아내려면 먼저 국경을 넘어야 합니다.
 
얼마나 큰 모델이 필요한지 알아내려면, 당신은 지나치게 적합한 모델을 개발해야 합니다. 5장에서 학습한 바와 같이 이 작업은 매우 쉽습니다. 
1. 레이어를 추가합니다. 
1. 층을 크게 만드세요. 
1. 더 많은 시대를 위해 훈련하세요. 

교육 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 교육 및 검증 값도 항상 모니터링합니다. 검증 데이터에 대한 모형의 성능이 저하되기 시작하면 과적합이 이루어진 것입니다.

### **2.5 모델 정규화 및 조정**

일단 통계적 힘을 얻고 오버핏을 할 수 있게 되면, 여러분은 올바른 길을 가고 있다는 것을 알게 됩니다. 이때 일반화 성능을 최대화하는 것이 목표입니다. 

이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 교육하고 검증 데이터(현 시점에서 테스트 데이터가 아님)를 평가한 다음 다시 수정하고 반복합니다. 다음과 같은 몇 가지 방법을 시도해 보십시오. 
* 다양한 아키텍처를 시도하고 레이어를 추가 또는 제거합니다.
* 탈락 추가.
* 모형이 작은 경우 L1 또는 L2 정규화를 추가합니다.
* 최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(예: 계층당 단위 수 또는 최적화 프로그램의 학습 속도)를 사용해 보십시오.
* 선택적으로 데이터 큐레이션 또는 기능 엔지니어링을 반복할 수 있습니다. 더 많은 데이터를 수집하고 주석을 달거나, 더 나은 기능을 개발하거나, 유용한 것으로 보이지 않는 기능을 제거합니다. 

Keras와 같은 "자동화된 하이퍼 파라미터 튜닝 소프트웨어"를 사용하여 이 작업의 상당 부분을 자동화할 수 있습니다.튜너. 13장에서 다루도록 하겠습니다. 

검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모형에 유출됩니다. 몇 번만 반복해도 무해하지만, 여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 교육을 받은 모델이 없음에도 불구하고 결국 모델이 검증 프로세스에 과도하게 적합하게 됩니다. 이것은 평가 과정의 신뢰성을 떨어뜨립니다. 

만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터(교육 및 검증)에 대해 최종 생산 모델을 교육하고 테스트 세트에서 마지막으로 평가할 수 있습니다. 테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했음을 의미할 수 있습니다. 이 경우 K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환할 수 있습니다.

## **3. 모델 배포**

귀하의 모델은 테스트 세트에 대한 최종 평가를 성공적으로 마쳤습니다. 이제 배치하고 생산적인 수명을 시작할 준비가 되었습니다.

### **3.1 이해관계자에게 업무를 설명하고 기대치를 설정**

성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 실제로 제공하는 시스템은 그 그림의 절반에 불과합니다. 나머지 절반은 출시 전 적절한 기대치를 설정하고 있다.

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적이다. 예를 들어, 그들은 시스템이 과제를 "이해"하고 과제 맥락에서 인간과 같은 상식을 행사할 수 있다고 기대할 수 있다. 이 문제를 해결하려면 모형의 고장 모드의 몇 가지 예제를 보여 주는 것을 고려해야 합니다(예: 잘못 분류된 표본, 특히 잘못 분류된 표본이 놀라울 수 있는 표본 등).

또한 특히 이전에 사람이 처리했던 프로세스의 경우 인간 수준의 성능을 기대할 수 있습니다. 대부분의 머신러닝 모델은 인간이 만든 라벨에 근접하도록 (불완전하게) 훈련되었기 때문에 거의 도달하지 못한다. 모델 성능 기대치를 명확히 전달해야 합니다. "모델은 98%의 정확도를 가지고 있다"(대부분의 사람들이 정신적으로 최대 100%까지 반올림한다)와 같은 추상적인 문장을 사용하는 것을 피하고, 예를 들어, 잘못된 부정 비율과 잘못된 긍정 비율에 대해 이야기하는 것을 선호한다. "이러한 설정을 사용하면 부정 행위 탐지 모델은 5%의 거짓 음성 비율과 2.5%의 거짓 양성률을 갖습니다. 매일 평균 200건의 유효거래가 사기행위로 플래그가 지정돼 수작업 검토를 위해 발송되고, 평균 14건의 사기거래가 누락됐다. 평균 266건의 부정거래가 적발될 것이다." 모델의 성능 측정 기준을 비즈니스 목표와 명확하게 연관시킵니다.

또한 주요 시작 매개 변수(예: 트랜잭션에 플래그를 지정해야 하는 확률 임계값(임계값이 다르면 거짓 음수 및 거짓 긍정 비율이 다름)를 선택할 것인지 이해 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 맥락을 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다.

### **3.2 추론 모델 발송**

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 콜랩 노트북에 도착해도 끝나지 않습니다. 교육 중에 조작한 것과 동일한 파이썬 모델 객체를 프로덕션으로 넣는 경우는 거의 없습니다.

먼저 Python이 아닌 다른 것으로 모델을 내보내는 것이 좋습니다. 
* 운영 환경에서 Python을 전혀 지원하지 않을 수 있습니다(예를 들어, 모바일 앱이나 임베디드 시스템인 경우).
* 나머지 앱이 Python이 아닌 경우(JavaScript, C++ 등) 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생할 수 있습니다. 

둘째, 생산 모델은 교육용이 아니라 예측(추론이라고 하는 단계) 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다. 

이제 사용 가능한 다양한 모델 구축 옵션을 간단히 살펴보겠습니다.

**REST API로 모델 배포**

이것은 아마도 모델을 제품으로 바꾸는 일반적인 방법일 것이다: 서버나 클라우드 인스턴스에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 쿼리한다. 플라스크(또는 다른 파이썬 웹)와 같은 것을 사용하여 자신만의 서빙 앱을 만들 수 있습니다. 
TensorFlow 서빙이라는 API로 모델을 제공하기 위해 TensorFlow의 자체 라이브러리를 사용합니다. TensorFlow 서빙(www.tensorflow.org/tfx/guide/serving)을 사용하여 Keras 모델을 몇 분 내에 배포할 수 있습니다. 

다음과 같은 경우 이 배포 설정을 사용해야 합니다. 
* 모델의 예측을 사용할 애플리케이션은 인터넷에 안정적으로 액세스할 수 있습니다(확실히). 예를 들어 응용 프로그램이 모바일 응용 프로그램인 경우 원격 API에서 예측을 제공한다는 것은 응용 프로그램을 비행기 모드나 저연결 환경에서 사용할 수 없음을 의미합니다.
* 응용 프로그램에는 엄격한 대기 시간 요구사항이 없습니다. 요청, 추론 및 응답 왕복에는 일반적으로 약 500ms가 소요됩니다. 
* 추론을 위해 전송된 입력 데이터는 그다지 민감하지 않습니다. 즉, 데이터는 모델에서 확인할 필요가 있으므로 해독된 형태로 서버에서 사용할 수 있어야 합니다(그러나 HTTP 요청 및 응답에는 SSL 암호화를 사용해야 함). 

예를 들어 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용카드 사기 탐지 프로젝트, 위성 이미지 프로젝트는 모두 REST API를 통해 서비스하기에 적합합니다. 

REST API로 모델을 배포할 때 중요한 질문은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부입니다. 예를 들어 구글 제품인 클라우드 AI 플랫폼은 텐서플로우 모델을 구글 클라우드 스토리지(GCS)에 업로드하면 이를 쿼리할 수 있는 API 끝점을 제공한다. 일괄 처리 예측, 로드 밸런싱 및 확장과 같은 많은 실제적인 세부 사항을 처리합니다.

**장치에 모델 배포**

때로는 스마트폰, 로봇의 내장형 ARM CPU 또는 작은 장치의 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용해야 할 수도 있습니다. 예를 들어, 여러분은 이미 카메라에서 직접 실행되는 작은 딥러닝 모델이었던, 여러분이 지목한 장면에서 사람과 얼굴을 자동으로 감지할 수 있는 카메라를 본 적이 있을 것입니다. 

다음과 같은 경우 이 설정을 사용해야 합니다. 
* 모델은 엄격한 지연 시간 제약이 있거나 연결성이 낮은 환경에서 실행해야 합니다. 몰입형 증강 현실 애플리케이션을 구축하는 경우 원격 서버를 쿼리하는 것은 실행 가능한 옵션이 아닙니다. 
* 모델은 대상 장치의 메모리 및 전력 제약 조건 하에서 실행될 수 있을 정도로 충분히 작게 만들 수 있습니다(TensorFlow Model Optimization Toolkit:(10)을 사용하여 이 문제를 해결할 수 있습니다).
* 가능한 한 높은 정확도를 얻는 것이 업무에 중요한 것은 아닙니다. 런타임 효율성과 정확성 사이에는 항상 균형이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델보다 좋지 않은 모델을 제공해야 하는 경우가 많습니다. 
* 입력 데이터는 엄격하게 중요하므로 원격 서버에서 해독할 수 없습니다. 

예를 들어, 스팸 탐지 모델은 최종 사용자의 스마트폰에서 채팅 앱의 일부로 실행되어야 하는데, 이는 메시지가 종단 간 암호화되어 원격으로 호스팅된 모델에서 전혀 읽을 수 없기 때문이다. 마찬가지로 불량 쿠키 탐지 모델도 엄격한 대기 시간 제약이 있어 공장에서 실행해야 합니다. 다행히 이 경우 전력이나 공간 제약이 없어 GPU에서 실제로 모델을 실행할 수 있습니다. 

스마트폰이나 임베디드 장치에 Keras 모델을 배포하려면 TensorFlow Lite(www.tensorflow.org/lite)를 사용해야 합니다. ARM64 기반 컴퓨터, 라즈베리 파이 또는 특정 마이크로컨트롤러뿐만 아니라 Android 및 iOS 스마트폰에서 실행되는 효율적인 장치 딥러닝 추론을 위한 프레임워크입니다. Keras 모델을 TensorFlow Lite 형식으로 바로 전환할 수 있는 변환기가 포함되어 있습니다.

**브라우저에서 모델 배포**

딥 러닝은 브라우저 기반 또는 데스크톱 기반 자바스크립트 응용 프로그램에서 자주 사용됩니다. 응용 프로그램이 REST API를 통해 원격 모델을 쿼리하는 것이 보통 가능하지만 대신 사용자의 컴퓨터에서 직접 모델을 실행할 수 있는 주요 이점이 있을 수 있다. 

다음 경우에 이 설정을 사용합니다. 
* 컴퓨팅을 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있습니다.
* 입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 합니다. 예를 들어 스팸 탐지 프로젝트에서 채팅 앱의 웹 버전과 데스크톱 버전(JavaScript로 작성된 크로스 플랫폼 앱으로 구현됨)은 로컬에서 실행되는 모델을 사용해야 합니다.
* 애플리케이션에는 엄격한 지연 시간 제약이 있습니다. 최종 사용자의 노트북이나 스마트폰에서 실행되는 모델은 서버의 대형 GPU에서 실행되는 모델보다 속도가 느릴 수 있지만, 추가 100ms의 네트워크 왕복 시간이 없습니다.
* 모델이 다운로드되고 캐시된 후에도 연결 없이 계속 작동하려면 앱이 필요합니다. 

물론 모델이 사용자의 노트북이나 스마트폰의 CPU, GPU 또는 RAM을 독점하지 않을 정도로 작은 경우에만 이 옵션을 사용해야 합니다. 또한 전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 비밀로 유지할 필요가 없도록 해야 합니다. 훈련된 딥러닝 모델이 주어지면 일반적으로 훈련 데이터에 대한 일부 정보를 복구할 수 있다는 사실에 유의하십시오. 중요한 데이터에 대해 훈련된 모델은 공개하지 않는 것이 좋습니다. 

자바스크립트에서 모델을 배포하기 위해 텐서플로우 생태계는 TensorFlow.js(www.tensorflow.org/js),는 거의 모든 Keras API(원래 WebKeras라는 작업 이름으로 개발됨)뿐만 아니라 많은 하위 수준의 TensorFlow API를 구현한다. 저장된 Keras 모델을 TensorFlow.js로 쉽게 가져와 브라우저 기반 JavaScript 앱 또는 데스크톱 전자 앱의 일부로 쿼리할 수 있습니다.

**추론 모형 최적화**

사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 특히 중요합니다. TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다. 

적용할 수 있는 두 가지 일반적인 최적화 기법이 있습니다. 
* 체중 가지치기: 체중 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아니다. 가장 중요한 항목만 유지하면 모델의 계층에서 매개변수 수를 크게 줄일 수 있습니다. 따라서 성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 설치 공간을 줄일 수 있습니다. 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있습니다.
* 체중 정량화: 딥 러닝 모델은 단일 정밀 부동 소수점(float32 ) 가중치를 사용하여 훈련된다. 그러나 가중치를 8비트 부호 정수(int8)로 정량화하면 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있다. 

TensorFlow 생태계는 Keras API와 긴밀하게 통합된 가중치 정리 및 정량화 툴킷(www.tensorflow.org/model 최적화)을 포함한다.

### **3.3 야생에서 모델 모니터링**

추론 모델을 내보내고 이를 애플리케이션에 통합한 후 프로덕션 데이터에 대해 시운전을 수행했습니다. 모델이 예상대로 작동합니다. 유닛 테스트와 로깅 및 상태 모니터링 코드를 완벽하게 작성했습니다. 이제 큰 빨간색 버튼을 눌러 실운영에 투입할 차례입니다. 

심지어 이것이 끝이 아닙니다. 모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 합니다. 
* 새로운 음악 추천 시스템을 구축한 후 온라인 라디오에 대한 사용자 참여가 증가했습니까, 아니면 감소했습니까? 새로운 클릭률 예측 모델로 전환한 후 평균 광고 클릭률이 증가했습니까? 랜덤 A/B 검정을 사용하여 모델 자체의 영향을 다른 변경으로부터 분리하는 것을 고려하십시오. 사례의 일부는 새 모형을 통과해야 하고 다른 제어 부분 집합은 이전 공정을 고수해야 합니다. 충분히 많은 사례가 처리되면, 두 사례의 결과 차이는 모델에 기인할 가능성이 높다.
* 가능하면 생산 데이터에 대한 모델의 예측에 대해 정기적인 수동 감사를 실시합니다. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있습니다. 생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교합니다. 예를 들어 이미지 검색 엔진과 잘못된 쿠키 플래그 지정 시스템에 대해 이 작업을 수행해야 합니다.
* 수동 감사가 불가능한 경우, 사용자 설문 조사와 같은 대안적인 평가 방법(예: 스팸 및 유해 콘텐츠 플래그 지정 시스템의 경우)을 고려하십시오.

### **3.4 모델 유지** 

마지막으로, 영원한 모델은 없습니다. 컨셉 드리프트에 대해 이미 배웠습니다. 시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하됩니다. 음악 추천 시스템의 수명이 몇 주 내로 계산됩니다. 신용카드 사기 탐지 시스템의 경우 며칠이 걸릴 수 있습니다. 이미지 검색 엔진을 위한 최고의 경우 2년입니다. 

모델이 출시되자마자 모델을 대체할 다음 세대를 교육할 준비를 해야 합니다. 이와 같이: 
* 생산 데이터의 변화를 주의합니다. 새로운 기능을 사용할 수 있습니까? 레이블 세트를 확장해야 합니까, 그렇지 않으면 편집해야 합니까? 
* 데이터를 계속 수집하고 주석을 달 수 있으며, 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있습니다. 특히 현재 모형에 대해 분류하기 어려운 표본을 수집하는 데 특히 주의해야 합니다. 이러한 표본은 성능을 향상시키는 데 도움이 될 가능성이 높습니다. 

이것으로 머신러닝의 보편적인 워크플로를 마칩니다. 명심해야 할 사항이 많습니다. 전문가가 되기 위해서는 시간과 경험이 필요하지만 걱정하지 마세요, 여러분은 이미 몇 장 전보다 훨씬 더 현명해졌습니다. 이제 기계 학습 프로젝트에 수반되는 전체 스펙트럼이라는 큰 그림에 익숙해졌습니다. 이 책의 대부분은 모델 개발 부분에 초점을 맞추지만, 이제 전체 워크플로우의 일부분에 불과하다는 것을 알게 되었습니다. 항상 큰 그림을 명심하세요!

## **4. 요약** 
* 새로운 머신러닝 프로젝트를 수행할 때 먼저 당면한 문제를 정의합니다. 
 * 해야 할 일의 광범위한 맥락을 이해합니다. 최종 목표는 무엇이며 제약은 무엇입니까?
 * 데이터 세트를 수집하고 주석을 달 수 있습니다. 데이터를 자세히 이해해야 합니다.
 * 문제에 대한 성공을 어떻게 측정할 것인지, 어떤 메트릭스에서 모니터링할 것인지 선택합니다. 
당신의 검증 데이터? 
* 문제를 이해하고 적절한 데이터 세트를 확보하면 모델을 개발합니다. 
 * 데이터를 준비합니다.
 * 평가 프로토콜을 선택하십시오. 홀드-아웃 검증? K-폴드 검증? 검증에 사용할 데이터 부분은 어느 정도입니까?
 * 통계적 능력을 달성하라: 단순한 기준선을 이긴다.
 * 스케일업: 오버핏 가능한 모델을 개발합니다.
 * 검증 데이터의 성능에 따라 모델을 정규화하고 하이퍼 파라미터를 조정합니다. 많은 머신러닝 연구는 이 단계에만 집중하는 경향이 있으며 큰 그림을 염두에 두고 있습니다.
* 모델이 준비되고 테스트 데이터에 대해 우수한 성능을 제공하면 이제 구현할 차례입니다. 
 * 먼저 이해 관계자들과 적절한 기대치를 설정했는지 확인합니다.
 * 추론을 위해 최종 모델을 최적화하고 웹 서버, 모바일, 브라우저, 임베디드 디바이스 등의 배포 환경에 모델을 전달합니다.
 * 모델의 생산 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델을 개발할 수 있습니다.
