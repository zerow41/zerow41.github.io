

# **머신러닝 작업 흐름**
<br>
<br>
현실 세계에서는 프로그램에 지정된 데이터 세트이 존재하거나 모델 훈련을 즉시 시작하는 경우가 적음<br>
* 사진을 공유하는 소셜 네트워크 유형의 개인화된 사진 검색 엔진으로, 수동으로 태그할 필요 없이 모든 사진을 검색
* 채팅 앱의 게시물 중 스팸 및 불쾌한 텍스트 콘텐츠 플래그 표시
* 온라인 라디오 사용자를 위한 음악 추천 시스템 구축
* 전자상거래 웹 사이트에 대한 신용카드 사기 탐지.
* 주어진 시간에 주어진 사용자에게 어떤 광고를 제공할 것인지 결정하기 위해 광고 클릭률을 예측
* 쿠키 제조라인 컨베이어 벨트에 이상 쿠키 플래그 지정
* 위성 이미지를 사용하여 아직 알려지지 않은 고고학 유적지의 위치를 예측
<br>
<br>
머신러닝의 흐름은 보통 크게 세 부분으로 구성된다.
+ **과제 정의**: 문제와 고객에게 필요한 비즈니스 논리를 이해, 데이터 수집 및 파악 후 성능 평가 방법 선택
+ **모델 개발**: 머신러닝 모델 준비, 평가 방법과 기준선을 선택하여 과대적합이 가능한 일반화 능력을 갖춘 첫 번째 모델 훈련(가능한 한 최고의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정)
+ **모델 배포**: 고객에게 모델 전달. 실제 모델의 성능 모니터링 및 차세대 모델을 구축하는 데 필요한 데이터 수집
<br>
<br>
<br>
## **1. 문제 정의**
하고 있는 일의 맥락을 깊게 이해하지 않고는 좋은 모델을 만들 수 없음. <br>
> 고객이 왜 문제를 해결하려고 하는지<br>
> 해결하면 어떤 결과를 얻는지<br>
> 모델이 어떻게 사용되고 비즈니스에 어떻게 적용될 것 같은지<br>
> 어떤 종류의 데이터를 사용하고 수집할 수 있는지<br>
> 비즈니스 문제에 사용될 머신러닝 과제는 무엇인지

### **1.1 문제 구체화하기** 

머신러닝 문제를 구체화하기 위해 고객과 많은 대화가 필요
+ 입력 데이터는 무엇이고 어떤 예측 결과가 필요한가? : 데이터 가용성을 제한하고, 직접 데이터를 수집해 주석 달기
+ 어떤 유형의 머신러닝인가? : 이항 분류/다중 클래스 분류/스칼라 또는 벡터 회귀/강화 학습 등 또는 머신러닝을 사용하지 않아도 되는지
  + 사진 검색 엔진 프로젝트 - 멀티클래스, 멀티라벨 분류
  + 스팸 탐지 프로젝트 - 이진 분류(또는 3원 분류)
  + 음악 추천 엔진 - 딥 러닝이 아닌 매트릭스 인수분해(협업 필터링)를 통해 더 잘 처리
  + 카드 사기 탐지 사업 - 이진 분류
  + 클릭률 예측 프로젝트 - 스칼라 회귀
  + 이상 쿠키 탐지 - 이진 분류 작업(객체 탐지 모델이 필요)
  + 위성 이미지에서 새로운 고고학 유적지를 찾는 프로젝트 - 이미지 유사성 순위 매기기 
+ 기존 해결법은 어떤 형태인가? : 어떤 시스템이 구축되어 있는지, 작동법은 어떤지 이해
+ 특별한 제약 조건이 있는가? : 세부적인 상황에서 지연 시간 제약까지 다양
<br>
조사 후 가설 설정.<br>
모델을 갖추기 전까지는 가설일 뿐이며 검증되거나 무효화 될 수 있음.
+ 입력이 주어지면 목표를 예측 가능
+ 사용 가능한(또는 곧 수집할) 데이터가 입력과 대상 간의 관계를 학습하는 데 충분한 정보를 제공

### **1.2 데이터세트 모으기**

다음은 가장 오래 걸리고 비용이 많이 드는 데이터 수집 단계<br>
좋은 모델을 만들기 위해서는 알고리즘 보다도 많은 데이터가 필요<br>
모델의 일반화 기능은 거의 전적으로 모델의 데이터(보유한 데이터 포인트 수, 레이블의 안정성, 기능의 품질 등)에 따라 학습<br>
* 사진 검색 엔진 프로젝트 - 분류하려는 레이블 세트를 선택, 10,000개의 공통 이미지 카테고리를 설정. 이 세트의 레이블로 사용자가 업로드한 과거 이미지 수십만 개에 수동으로 태그를 지정
* 채팅앱 스팸탐지 사업 - 사용자 대화는 암호화되어 있어 모델 훈련에 사용 불가, 별도의 액세스 권한을 얻어 수만 개의 공개 게시물에 대한 데이터 세트를 수동으로 태그하고 스팸, 불쾌감 또는 허용 가능한 태그를 지정
* 음악 추천 엔진 & 클릭률 예측 프로젝트 - 사용자의 기록을 사용, 새로운 데이터를 수집할 필요 없음
* 쿠키 flagging 모델 - 컨베이어 벨트에 카메라를 설치해 수만 개의 이미지를 수집, 수동으로 이 이미지에 레이블을 붙여야 함. (공장 사람들 훈련 시키기)
* 위성사진 프로젝트 - 수천 개 장소의 데이터 베이스를 수집, 각 장소에 대해 다른 기상 조건에서 찍은 기존 위성 사진도 필요.
<br>
<br>
**데이터 주석 환경에 투자하기**<br>
지도 학습을 수행하는 경우 입력(예: 이미지) 수집 후, 입력에 대한 주석(예: 모델이 예측할 목표)이 필요<br>
데이터 주석 공정에 따라 모델의 품질을 결정<br>
* 라벨을 모으기 위해 Mechanical Turk와 같은 크라우드소싱 플랫폼을 사용해야 하는가?
* 데이터 레이블링 전문 회사의 서비스를 사용해야 하는가? 
아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제가 어려움
<br>
<br>
최상의 옵션을 선택을 위해 작업 중인 제약 조건 고려해야 함
* 데이터 레이블 작성자가 전문가여야 하는가?또는 데이터에 주석을 달 수 있는 사람이 있는가? 
* 데이터에 주석을 달 때 전문 지식을 교육할 수 있는가? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있는가?
* 전문가가 주석을 작성하는 방법을 알고 있는가? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없다.
<br>
데이터에 레이블을 붙이기로 결정한 경우 주석을 작성하는데 어떤 소프트웨어를 사용할 것인가도 중요<br>
직접 만들어야 할 수도 있지만, 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있음
<br>
<br>
**비대표 데이터 주의하기**<br>
머신러닝 모델은 이전에 본 것과 비슷한 입력만 이해할 수 있어 훈련에 사용되는 데이터는 생산 데이터의 "**대표**"여야 함<br>
가능하면 모델이 사용될 환경에서 직접 데이터를 수집<br>
생산 데이터에 대한 훈련이 가능하지 않다면 훈련 데이터와 생산 데이터가 어떻게 다른지 이해하고 차이를 수정 <br>
머신러닝은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 주의
<br>
*Concpet drift*
> * 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생 : 과거 데이터의 표현 방법이 현재와 달라 모델이 제대로 수행되지 못할 가능성이 높음<br>
> * 변화가 빠르게 자주 발생하는 경우 극심함<br>
> * 해결을 위해 지속적인 데이터 수집, 주석 및 모델 재교육이 필요
<br>
*샘플링 편향의 문제* : 샘플링 편향은 데이터 수집 과정에서 예측하려는 것과 상호작용할 때 발생

### **1.3 데이터 이해하기**

모델 훈련 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고 잠재적인 문제를 선별 
* 데이터에 이미지 또는 자연어 텍스트가 포함되어 있는 경우 : 샘플 몇 개(및 해당 레이블)를 직접 살펴보기
* 데이터에 숫자 모양이 포함되어 있는 경우 : 모양의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다른 값의 빈도를 파악하기
* 데이터에 위치 정보가 포함되어 있는 경우 : 지도에 표시하여 뚜렷한 패턴 확인하기
* 일부 샘플에 일부 형상에 대한 결측값이 있는 경우 : 데이터를 준비할 때 해결
* 분류 문제일 경우 : 데이터에 있는 각 클래스의 인스턴스 수를 파악하기(클래스가 비슷하게 표현되지 않는다면 불균형이 있을 수 있음)
* "타겟 누수(target leaking)"가 있는 경우 : 실제로 운영에서 데이터에 사용할 수 없는 대상(암호화된 정보)에 대한 정보를 제공하는지 확인하기, 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 확인

### **1.4 성공 평가 방법 선택하기**

프로젝트에서 성공을 거두려면 먼저 성공 정의가 필요<br>
성공을 위한 지표는 프로젝트 전반에 걸쳐 모든 기술적 선택에 영향을 미침<br>
이 지표는 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 함<br>
> + 모든 클래스가 동일한 확률의 균형 분류 문제의 경우 : "수신기 조작 특성 곡선(ROC AUC)" 아래의 정확도와 영역이 일반적인 지표이다.<br>
> + 클래스 불균형 문제, ranking 문제, 다중 레이블 분류의 경우 : 정밀도 및 재현율 뿐만 아니라 가중치의 정확도 또는 ROC AUC를 사용할 수 있다.<br>
> + 또는 자신만의 사용자 지정 메트릭을 정의해야 하는 경우
<br>
<br>
<br>
## **2. 모델 개발** 
진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있음

### **2.1 데이터 준비**
데이터 전처리는 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 함<br>
벡터화, 정규화, 결측값 처리 등<br>
이때 전처리 기술은 도메인마다 다름(예: 텍스트 데이터 또는 이미지 데이터)
<br>
<br>
**벡터화**<br>
신경망의 모든 입력과 target은 일반적으로 부동소수점 데이터의 텐서(또는 특정 경우 정수나 문자열 텐서)여야 함 <br>
데이터 벡터화 : 소리, 이미지, 텍스트 등의 데이터를 텐서로 전환하는 것.
<br>
<br>
**값 정규화**<br>
일반적으로 사용하는 신경망 데이터나 이기종 데이터(예: 한 특징이 0-1이고 다른 특징이 100-200인 데이터)에 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 입력하는 것은 안전하지 않음<br> 
<br>
네트워크에서 보다 쉽게 학습하기 위해 필요한 데이터의 특성
* 작은 값 사용 - 일반적으로 대부분의 값은 0-1 범위여야 한다.
* 균일화 - 즉, 모든 형상이 거의 동일한 범위의 값을 가져야 한다.
<br>
일반적인 엄격한 정규화 방법 : 항상 필요한 것은 아님 
* 평균이 0이 되도록 각 특성을 독립적으로 정규화한다. 
* 표준 편차가 1이 되도록 각 특성을 독립적으로 정규화한다.

```python
# NumPy array로 정규화 하기
x -= x.mean(axis=0)
x /= x.std(axis=0)
```
<br>
<br>
**결측값 처리**<br>
데이터에 결측값이 있을 수 있음, 결측값을 완전히 삭제할 수도 있지만 반드시 삭제할 필요는 없음 
* 특성이 범주형인 경우 : "값이 누락됨"을 의미하는 새 범주 생성(모델은 타겟에 대해 이것이 내포하는 의미를 자동으로 학습)
* 특성이 숫자일 경우 : "0"과 같은 임의의 값을 입력하지 않음, 모델 일반화에 어려움이 생겨 데이터의 평균값 또는 중위값으로 바꾸는 것이 좋음 <br>

### **2.2 평가 규약(evaluation protocol) 선택** 

평가 규약의 목표는 실제 생산 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것<br>
세 가지 일반적인 평가 프로토콜
* 홀드아웃 유효성 검사 세트 유지 - 데이터가 많을 때 사용하는 방법 
* K-폴드 교차 검증 수행 - 홀드아웃 유효성 검사가 신뢰할 수 없을 정도로 샘플 수가 적을 때 올바른 선택 
* 반복 K-폴드 검증 수행 - 데이터가 거의 없을 때 매우 정확한 모델 평가 수행 <br>
검증 세트의 대표성에 유의하고 훈련 세트와 검증 세트 사이에 중복 샘플이 없도록 해야 함

### **2.3 기준선 넘기기** 

모델 자체에 대한 작업을 시작하면 간단한 기준선을 능가할 수 있는 작은 모델 개발 필요<br>
가장 중요한 세 가지
* 특성 공학 : 정보가 없는 특성(특성 선택)을 걸러내고 문제에 대한 지식을 활용해 유용한 새로운 특성을 개발 
* 올바른 아키텍처 양식 선택 : 어떤 유형의 모델 아키텍처를 사용하는가? 딥러닝은 과제를 위한 좋은 접근법인가, 아니면 다른 것을 사용해야 하는가? 
* 충분히 좋은 훈련 구성 선택 : 어떤 손실 함수를 사용해야 하는가? 배치 크기와 학습률은 어떻게 되는가?
<br>
*올바른 손실 기능 선택*<br>
문제에 대한 성공을 측정하는 메트릭에 대해 직접 최적화하지 못하는 경우가 많음 <br>
메트릭을 손실 함수로 바꾸는 쉬운 방법이 없을 때도 있음 <br>
손실 함수는 미니 배치가 주어져야 하며, 역전파를 사용하여 네트워크를 훈련시킬 수 없어야 함<br>
<br>
대부분의 문제에서 시작할 수 있는 기존 형식이 있음<br>
선행 기술을 조사하여 작업에서 가장 잘 수행할 수 있는 기능 엔지니어링 기술과 모델 아키텍처를 탐색하기<br>
<br>
검증력을 만족하는 것이 항상 가능한 것은 아<br>
합리적인 아키텍처를 여러 번 시도해도 단순한 기준선을 넘을 수 없다면 입력 데이터에 질문에 대한 답이 없는 것일 수 있음<br>
아래의 가설들이 거짓일 가능성이 높으며, 이 경우 처음부터 다시 시작해야 함<br>
* 입력이 주어지면 출력을 예측할 수 있음 
* 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공

### **2.4 Scale up: 과대 적합 모델 개발**

머신러닝의 보편적인 갈등은 최적화와 일반화 사이에서 발생<br>
이상적인 모델은 과소적합과 과대적합, 과소용량과 과대용량 사이의 경계에 서 있는 모델<br>
이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어야 함<br>
<br>
과대적합 모델을 개발해야 함, 검증 데이터에 대한 모델의 성능이 저하되기 시작하면 과대적합이 일어난 것<br>
과대적합 모델 개발 방법
1. 레이어 추가
1. 층 크기 키우기
1. 더 많은 에포크로 훈련

### **2.5 모델 정규화 및 조정**

검증력을 얻고 과대적합을 할 수 있게 되면, 일반화 성능을 최대화하는 것을 목표로 해야 함<br>
모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정 및 훈련하고 검증 데이터를 평가한 다음 다시 수정하고 반복 <br>
"자동 하이퍼 파라미터 튜닝 소프트웨어(KerasTuner)"를 사용하여 이 작업의 상당 부분을 자동화 가능
* 다양한 아키텍처를 시도하고 레이어를 추가 또는 제거
* dropout 규제 추가
* 모델이 작은 경우 L1 또는 L2 정규화 적용
* 최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(계층당 단위 수 또는 최적화 프로그램의 학습 속도)를 사용
* 선택적으로 데이터 큐레이션 또는 기능 엔지니어링을 반복(더 많은 데이터를 수집하고 주석을 달거나, 더 나은 기능을 개발하거나, 유용한 것으로 보이지 않는 기능을 제거)
<br>
검증 프로세스의 피드백을 사용하여 모델을 조정할 때마다 검증 프로세스에 대한 정보가 모델에 유출<br>
여러 반복에 걸쳐 체계적으로 수행되면 모델에 과대적합이 발생하고 평가 과정의 신뢰성을 떨어뜨림<br>
<br>
만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터(훈련 및 검증)에 대해 최종 생산 모델을 훈련하고 테스트 세트에서 마지막으로 평가<br>
테스트 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 더 안좋게 판명되는 경우<br>
+ 검증 절차를 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했음을 의미
+ 해결법 : K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환
<br>
<br>
<br>
## **3. 모델 배포**
### **3.1 이해관계자에게 업무를 설명하고 기대치를 설정**

모델을 성공시키기 위해 아래의 사항에 주의하며 출시 전 적절한 기대치를 설정
+ 모델은 항상 정확하다는 비전문가들의 오해를 주의 : 모델의 실패 사례를 보여줘야 함
+ 모델 성능 기대치를 명확히 전달 : 추상적인 수치 사용을 피하고 거짓 부정 비율과 거짓 긍정 비율 등으로 설명
+ 모델의 성능 측정 기준을 비즈니스 목표와 명확히 연결
+ 주요 시작 매개 변수를 설정할 것인지 논의(trade off 포함)

### **3.2 추론 모델 전달**

1. Python이 아닌 다른 것으로 모델을 내보내는 것이 좋음
* 운영 환경에서 Python을 지원하지 않을 수 있음 : 모바일 앱이나 임베디드 시스템인 경우
* 나머지 앱이 Python이 아닌 경우(JavaScript, C++ 등) : 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생 가능 <br>
2. 생산 모델은 훈련용이 아니라 예측 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행
<br>
<br>
**REST API로 모델 배포**<br>
+ 모델을 제품으로 바꾸는 일반적인 방법
+ 서버나 클라우드 인스턴스에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 질의
+ Flask(또는 다른 파이썬 웹)와 같은 것을 사용하여 자신만의 서빙 앱 생성 가능 
+ TensorFlow Serving이라는 API로 모델을 제공하기 위해 TensorFlow의 자체 라이브러리를 사용
  + TensorFlow 서빙(www.tensorflow.org/tfx/guide/serving)을 사용하여 Keras 모델을 몇 분 내에 배포할 수 있음 
+ 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부가 중요
<br>
다음과 같은 경우 이 설정을 사용
* 모델의 예측을 사용할 애플리케이션은 인터넷에 안정적으로 액세스할 수 있는 경우 (비행기 모드나 저연결 환경에서 사용할 수 없음)
* 엄격한 대기 시간 요구사항이 없는 경우
* 추론을 위해 전송된 입력 데이터는 그다지 민감하지 않은 경우(데이터를 해독된 형태로 서버에서 사용할 수 있음)
* 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용카드 사기 탐지 프로젝트, 위성 이미지 프로젝트
<br>
<br>
**장치에 모델 배포**<br>
+ 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용
+ 스마트폰이나 임베디드 장치에 Keras 모델을 배포하려면 TensorFlow Lite(www.tensorflow.org/lite)를 사용
+ 예: 지목한 장면에서 사람과 얼굴을 자동으로 감지할 수 있는 카메라(카메라 + 딥러닝 모델) 
<br>
다음과 같은 경우 이 설정을 사용
* 모델은 엄격한 지연 시간 제약이 있거나 연결성이 낮은 환경에서 실행 : 몰입형 증강 현실 애플리케이션을 구축하는 경우 원격 서버를 쿼리하는 것 불가능
* 모델은 대상 장치의 메모리 및 전력 제약 조건 하에서 실행될 수 있을 정도로 충분히 작게 만들 수 있음(TensorFlow Model Optimization Toolkit:(10)을 사용하여 이 문제를 해결)
* 런타임 효율성과 정확성 사이에는 항상 균형이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델보다 좋지 않은 모델을 제공해야 하는 경우 
* 입력 데이터는 엄격하게 중요하므로 원격 서버에서 해독할 수 없음
<br>
<br>
**브라우저에서 모델 배포**<br>
+ 딥 러닝은 브라우저 기반 또는 데스크톱 기반 자바스크립트 응용 프로그램에서 자주 사용
+ 사용자의 컴퓨터에서 직접 모델을 실행할 수 있음 
+ 모델이 사용자의 노트북이나 스마트폰의 CPU, GPU 또는 RAM을 독점하지 않을 정도로 작은 경우에만 사용
+ 전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 비밀로 유지할 필요가 없도록 해야
+ 훈련된 딥러닝 모델이 주어지면 일반적으로 훈련 데이터에 대한 일부 정보를 복구할 수 있으므로 중요한 데이터가 포함된 훈련 모델은 공개하지 않는 것이 좋음
+ 자바스크립트에서 모델을 배포하기 위해 TensorFlow.js(www.tensorflow.org/js) 사용
<br>
다음 경우에 이 설정을 사용합니다. 
* 컴퓨팅을 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있음
* 입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 합니다.
* 애플리케이션에는 엄격한 지연 시간 제약이 있습니다. 
* 모델이 다운로드되고 캐시된 후에도 연결 없이 계속 작동하려면 앱이 필요합니다. 
<br>
<br>
**추론 모형 최적화**<br>
+ 사용 가능한 전력 및 메모리에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 중요
+ TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다. 
+ Keras API와 긴밀하게 통합된 가중치 정리 및 정량화 툴킷(www.tensorflow.org/model 최적화)을 포함
<br>
일반적으로 적용할 수 있는 두 가지 최적화 기법
* 가중치 가지치기: 가중치 텐서의 계수 중 가장 중요한 항목만 유지하면 모델의 계층에서 매개변수 수를 크게 줄일 수 있음
  * 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있음
* 가중치 정량화: 가중치를 8비트 부호 정수(int8)로 정량화하면 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있음 

### **3.3 모델 모니터링**

추론 모델을 내보내고 애플리케이션에 통합한 후 생산 데이터에 대해 모델이 예상대로 작동<br>
유닛 테스트와 기록 및 상태 모니터링 코드를 완벽하게 작성<br>
실운영에 투입하기<br>
<br>
모델을 구축한 후 지속적으로 
* 모델의 동작 모니터링
* 새 데이터에 대한 성능 모니터링
* 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 평가에 미치는 영향을 모니터링
  * 랜덤 A/B 검정(randomized A/B testing)을 사용하여 모델 자체의 영향을 다른 변경으로부터 분리하기 : 사례의 일부는 새 모델을 통과해야 하고 다른 제어 부분 집합은 이전 공정을 수행해야 함. 충분히 많은 사례가 처리되면, 두 사례의 결과 차이는 모델에 기인할 가능성이 높음
  * 가능하면 생산 데이터에 대한 모델의 예측에 대해 정기적인 수동 감사를 실시 : 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있음, 생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교
  * 수동 감사가 불가능한 경우 : 사용자 설문 조사와 같은 대안적인 평가 방법(예: 스팸 및 유해 콘텐츠 플래그 지정 시스템의 경우)을 고려

### **3.4 모델 유지** 

시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하됨<br>
모델이 출시되자마자 모델을 대체할 다음 세대를 훈련할 준비
* 생산 데이터의 변화를 주의 : 새로운 기능을 사용 가능한가? 레이블 세트를 확장해야 하는가, 편집해야 하는가? 
* 데이터를 계속 수집하고 주석을 달 수 있으며, 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있음 
* 현재 모델에 대해 분류하기 어려운 표본을 수집하는 데 특히 주의 : 성능을 향상시키는 데 도움이 될 가능성이 높음 
<br>
<br>
<br>
## **4. 요약** 
* 새로운 머신러닝 프로젝트를 수행할 때 먼저 당면한 문제를 정의 
  * 해야 할 일의 광범위한 맥락을 이해 : 최종 목표는 무엇이며 제약은 무엇인가?
  * 데이터 세트를 수집하고 주석을 달기 : 데이터 자세한 이해 필요
  * 문제에 대한 성공을 어떻게 측정할 것인지, 어떤 메트릭스에서 검증 데이터를 모니터링할 것인지 선택 
* 문제를 이해하고 적절한 데이터 세트를 확보하면 모델을 개발 
  * 데이터를 준비
  * 평가 방법을 선택 : 홀드-아웃 검증? K-폴드 검증? 검증에 사용할 데이터 부분은 어느 정도인가?
  * 검증력(statistical power)을 달성 : 단순한 기준선 넘기기
  * 스케일업: 과대적합 모델을 개발
  * 검증 데이터의 성능에 따라 모델을 정규화하고 하이퍼 파라미터를 조정
* 모델이 준비되고 테스트 데이터에 대해 우수한 성능을 제공하면 구현 시작
  * 이해 관계자들과 적절한 기대치를 설정했는지 확인
  * 추론을 위해 최종 모델을 최적화하고 웹 서버, 모바일, 브라우저, 임베디드 디바이스 등의 배포 환경에 모델을 전달
  * 모델의 생산 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델을 개발
